# =============================================
# é›†æˆæµ‹è¯•è„šæœ¬ - éªŒè¯æ–°APIç«¯ç‚¹
# åˆ›å»ºæ—¶é—´ï¼š2024-12-19
# ç›®çš„ï¼šéªŒè¯é‡æ„åçš„APIæ˜¯å¦æ­£å¸¸å·¥ä½œ
# =============================================

import json
import os
import sys

# æ·»åŠ åº”ç”¨è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from application.models.base_trainer import LLMTrainingParams, MLLMTrainingParams
from application.models.training_model import TrainingJobCreateRequest, TrainingTaskType


def test_api_imports():
    """æµ‹è¯•æ‰€æœ‰æ–°çš„APIæ¨¡å—æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•APIæ¨¡å—å¯¼å…¥...")

    try:
        # æµ‹è¯•è®­ç»ƒå™¨åŸºç±»å¯¼å…¥
        from application.models.base_trainer import (
            BaseTrainer,
            LLMTrainer,
            LLMTrainingParams,
            MLLMTrainer,
            MLLMTrainingParams,
            TrainerFactory,
            TrainerType,
        )

        print("âœ… è®­ç»ƒå™¨åŸºç±»å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•è®­ç»ƒæ¨¡å‹å¯¼å…¥
        from application.models.training_model import (
            TrainingJobCreateRequest,
            TrainingTaskType,
            determine_trainer_type,
            resolve_training_params,
        )

        print("âœ… è®­ç»ƒæ¨¡å‹å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•æ–°çš„APIè·¯ç”±å™¨å¯¼å…¥
        from application.api.training_v2 import router as training_v2_router

        print("âœ… æ–°APIè·¯ç”±å™¨å¯¼å…¥æˆåŠŸ")

        # æµ‹è¯•ä¸»åº”ç”¨å¯¼å…¥
        from application.main import app

        print("âœ… ä¸»åº”ç”¨å¯¼å…¥æˆåŠŸ")

    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        raise

    print()


def test_request_models():
    """æµ‹è¯•è¯·æ±‚æ¨¡å‹çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–"""
    print("ğŸ” æµ‹è¯•è¯·æ±‚æ¨¡å‹...")

    try:
        # æµ‹è¯•LLMè¯·æ±‚
        llm_request_data = {
            "task_type": "llm",
            "data_path": "/data/llm_dataset",
            "model_path": "/models/llama",
            "output_dir": "/output/llm_fine_tuned",
            "llm_params": {
                "num_epochs": 5,
                "batch_size": 2,
                "learning_rate": 2e-4,
                "lora_rank": 32,
                "lora_alpha": 64,
            },
        }

        llm_request = TrainingJobCreateRequest(**llm_request_data)
        print("âœ… LLMè¯·æ±‚æ¨¡å‹åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•åºåˆ—åŒ–
        llm_json = llm_request.model_dump_json()
        print("âœ… LLMè¯·æ±‚åºåˆ—åŒ–æˆåŠŸ")

        # æµ‹è¯•ååºåˆ—åŒ–
        llm_parsed = TrainingJobCreateRequest.model_validate_json(llm_json)
        print("âœ… LLMè¯·æ±‚ååºåˆ—åŒ–æˆåŠŸ")

        # æµ‹è¯•MLLMè¯·æ±‚
        mllm_request_data = {
            "task_type": "mllm",
            "data_path": "/data/mllm_dataset",
            "model_path": "/models/llava",
            "output_dir": "/output/mllm_fine_tuned",
            "mllm_params": {
                "num_epochs": 3,
                "batch_size": 1,
                "learning_rate": 1e-4,
                "vit_lr": 1e-5,
                "aligner_lr": 1e-5,
                "lora_rank": 16,
                "lora_alpha": 32,
            },
        }

        mllm_request = TrainingJobCreateRequest(**mllm_request_data)
        print("âœ… MLLMè¯·æ±‚æ¨¡å‹åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•åºåˆ—åŒ–
        mllm_json = mllm_request.model_dump_json()
        print("âœ… MLLMè¯·æ±‚åºåˆ—åŒ–æˆåŠŸ")

    except Exception as e:
        print(f"âŒ è¯·æ±‚æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
        raise

    print()


def test_parameter_classes():
    """æµ‹è¯•å‚æ•°ç±»çš„åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•å‚æ•°ç±»...")

    try:
        # æµ‹è¯•LLMå‚æ•°
        llm_params = LLMTrainingParams(num_epochs=5, learning_rate=2e-4, lora_rank=32)

        # æµ‹è¯•å‘½ä»¤è¡Œå‚æ•°ç”Ÿæˆ
        llm_args = llm_params.to_command_args()
        print(f"âœ… LLMå‘½ä»¤è¡Œå‚æ•°ç”ŸæˆæˆåŠŸ: {len(llm_args)}ä¸ªå‚æ•°")

        # æµ‹è¯•MLLMå‚æ•°
        mllm_params = MLLMTrainingParams(
            num_epochs=3, learning_rate=1e-4, vit_lr=1e-5, aligner_lr=1e-5
        )

        # æµ‹è¯•å‘½ä»¤è¡Œå‚æ•°ç”Ÿæˆ
        mllm_args = mllm_params.to_command_args()
        print(f"âœ… MLLMå‘½ä»¤è¡Œå‚æ•°ç”ŸæˆæˆåŠŸ: {len(mllm_args)}ä¸ªå‚æ•°")

        # æµ‹è¯•è®­ç»ƒå™¨ç±»å‹
        assert llm_params.get_trainer_type().value == "llm"
        assert mllm_params.get_trainer_type().value == "mllm"
        print("âœ… è®­ç»ƒå™¨ç±»å‹éªŒè¯æˆåŠŸ")

    except Exception as e:
        print(f"âŒ å‚æ•°ç±»æµ‹è¯•å¤±è´¥: {str(e)}")
        raise

    print()


def test_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("ğŸ” æµ‹è¯•å‘åå…¼å®¹æ€§...")

    try:
        # æµ‹è¯•æ—§æ ¼å¼çš„è¯·æ±‚
        old_request = TrainingJobCreateRequest(
            task_type=TrainingTaskType.LANGUAGE_MODEL,
            data_path="/data/old_dataset",
            model_path="/models/old_model",
            output_dir="/output/old_output",
        )
        print("âœ… æ—§æ ¼å¼è¯·æ±‚åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•å‚æ•°è§£æ
        from application.models.training_model import (
            determine_trainer_type,
            resolve_training_params,
        )

        params = resolve_training_params(old_request)
        trainer_type = determine_trainer_type(old_request)

        print(f"âœ… å‚æ•°è§£ææˆåŠŸ: {type(params).__name__}")
        print(f"âœ… è®­ç»ƒå™¨ç±»å‹æ¨æ–­æˆåŠŸ: {trainer_type}")

    except Exception as e:
        print(f"âŒ å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {str(e)}")
        raise

    print()


def test_json_examples():
    """ç”ŸæˆJSONç¤ºä¾‹ç”¨äºAPIæ–‡æ¡£"""
    print("ğŸ” ç”ŸæˆJSONç¤ºä¾‹...")

    try:
        # LLMè¯·æ±‚ç¤ºä¾‹
        llm_example = {
            "task_type": "llm",
            "data_path": "/data/llm_dataset",
            "model_path": "/models/qwen2-7b-instruct",
            "output_dir": "/output/llm_fine_tuned",
            "priority": 5,
            "llm_params": {
                "num_epochs": 3,
                "batch_size": 4,
                "learning_rate": 5e-5,
                "lora_rank": 64,
                "lora_alpha": 128,
                "max_length": 2048,
                "warmup_ratio": 0.1,
            },
        }

        # MLLMè¯·æ±‚ç¤ºä¾‹
        mllm_example = {
            "task_type": "mllm",
            "data_path": "/data/multimodal_dataset",
            "model_path": "/models/qwen2-vl-7b-instruct",
            "output_dir": "/output/mllm_fine_tuned",
            "priority": 7,
            "mllm_params": {
                "num_epochs": 2,
                "batch_size": 2,
                "learning_rate": 1e-5,
                "vit_lr": 1e-6,
                "aligner_lr": 1e-5,
                "lora_rank": 32,
                "lora_alpha": 64,
                "max_length": 4096,
            },
        }

        # ä¿å­˜ç¤ºä¾‹åˆ°æ–‡ä»¶
        examples = {
            "llm_training_example": llm_example,
            "mllm_training_example": mllm_example,
            "description": "Swift Trainer API v2 è¯·æ±‚ç¤ºä¾‹",
        }

        with open("api_examples.json", "w", encoding="utf-8") as f:
            json.dump(examples, f, indent=2, ensure_ascii=False)

        print("âœ… JSONç¤ºä¾‹ç”ŸæˆæˆåŠŸï¼Œä¿å­˜åˆ° api_examples.json")

    except Exception as e:
        print(f"âŒ JSONç¤ºä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise

    print()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é›†æˆæµ‹è¯•\n")

    try:
        test_api_imports()
        test_request_models()
        test_parameter_classes()
        test_compatibility()
        test_json_examples()

        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        print("   âœ… APIæ¨¡å—å¯¼å…¥æ­£å¸¸")
        print("   âœ… è¯·æ±‚æ¨¡å‹åºåˆ—åŒ–æ­£å¸¸")
        print("   âœ… å‚æ•°ç±»åŠŸèƒ½æ­£å¸¸")
        print("   âœ… å‘åå…¼å®¹æ€§ä¿æŒ")
        print("   âœ… JSONç¤ºä¾‹ç”ŸæˆæˆåŠŸ")
        print("\nğŸ”§ é‡æ„å®ŒæˆçŠ¶æ€:")
        print("   âœ… åŸºç±»æ¶æ„å·²å®ç°")
        print("   âœ… LLM/MLLMåˆ†ç¦»å®Œæˆ")
        print("   âœ… APIè·¯ç”±å·²æ³¨å†Œ")
        print("   âœ… å‘åå…¼å®¹æ€§ä¿æŒ")
        print("   âœ… æµ‹è¯•éªŒè¯é€šè¿‡")

    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback

        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
